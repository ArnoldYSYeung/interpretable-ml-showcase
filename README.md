# interpretable_ml_showcase
Showcase of Interpretable ML

##  Problem Statement
Say you're trying to classify between images of African and Indian elephants with a machine learning (ML) algorithm.  The ML algorithm can definitely tell you what it predicts a certain image is, but you have no way of verifying that the ML algorithm is correct.  Even more, you have no idea why it predicted the image as such.

##  Explainers
Explainers are methods which provide further details to justify the behaviour of a ML algorithm.  For example, if I wanted to know why the ML algorithm predicted a certain image to be of an African elephant, I can use different explainers to get different explanations justifying why the such a prediction is made.

Consider:
